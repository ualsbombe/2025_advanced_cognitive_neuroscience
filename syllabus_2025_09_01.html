<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Lau Møller Andersen">

<title>Syllabus - Advanced Cognitive Neuroscience - Autumn 2025</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="syllabus_files/libs/clipboard/clipboard.min.js"></script>
<script src="syllabus_files/libs/quarto-html/quarto.js"></script>
<script src="syllabus_files/libs/quarto-html/popper.min.js"></script>
<script src="syllabus_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="syllabus_files/libs/quarto-html/anchor.min.js"></script>
<link href="syllabus_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="syllabus_files/libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="syllabus_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="syllabus_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="syllabus_files/libs/bootstrap/bootstrap-71fc876df262dcb3b541b54c8daa28e0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#semester-plan" id="toc-semester-plan" class="nav-link active" data-scroll-target="#semester-plan">Semester plan</a></li>
  <li><a href="#textbooks" id="toc-textbooks" class="nav-link" data-scroll-target="#textbooks">Textbooks</a></li>
  <li><a href="#lectures-and-classes" id="toc-lectures-and-classes" class="nav-link" data-scroll-target="#lectures-and-classes">Lectures and classes</a></li>
  <li><a href="#workshop" id="toc-workshop" class="nav-link" data-scroll-target="#workshop">Workshop</a></li>
  <li><a href="#dependencies" id="toc-dependencies" class="nav-link" data-scroll-target="#dependencies">Dependencies</a></li>
  <li><a href="#portfolio-exams" id="toc-portfolio-exams" class="nav-link" data-scroll-target="#portfolio-exams">Portfolio exams</a></li>
  <li><a href="#feedback-practice" id="toc-feedback-practice" class="nav-link" data-scroll-target="#feedback-practice">Feedback practice</a></li>
  <li><a href="#from-the-academic-regulations" id="toc-from-the-academic-regulations" class="nav-link" data-scroll-target="#from-the-academic-regulations">From the academic regulations</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Syllabus - Advanced Cognitive Neuroscience - Autumn 2025</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Lau Møller Andersen </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="semester-plan" class="level4">
<h4 class="anchored" data-anchor-id="semester-plan">Semester plan</h4>
<p>Lecturer: Lau Møller Andersen</p>
<p>Lectures: Wednesdays 8-10 (1485-240)<br>
Classes: Thursdays 13-15 (1485-240)</p>
<p>Lectures will be a combination of students presenting on set topics and the lecturer presenting topics. The topics presented by the lecturer will be of a more technical nature, whereas the student-led topics will be more conceptual</p>
</section>
<section id="textbooks" class="level4">
<h4 class="anchored" data-anchor-id="textbooks">Textbooks</h4>
<p>The main textbook is: Puce A, Hari R (2023) MEG–EEG PRIMER, 2nd edition. Oxford University Press, Incorporated, United States. It can be purchased through Stakbogladen. Unlimited digital versions can also be borrowed from the Royal Library</p>
<p>Chapters from: Sekihara Kensuke, Nagarajan Srikatan S (2008) Adaptive Spatial Filters for Electromagnetic Brain Imaging, 1st ed.&nbsp;2008. Springer Berlin Heidelberg, Berlin, Heidelberg will also be used. Available online at the Royal Library</p>
<p>Puce and Hari’s introduction is a general and gentle conceptual introduction, whereas Sekihara and Nagajaran’s book is more equation oriented</p>
</section>
<section id="lectures-and-classes" class="level4">
<h4 class="anchored" data-anchor-id="lectures-and-classes">Lectures and classes</h4>
<div id="b1b860c4" class="cell" data-execution_count="1">
<div class="cell-output cell-output-stdout">
<pre><code>Week 36:
Lesson 0: What is it all about?
Class 0: Setting up UCloud and installing MNE-Python
Readings: Chapters 1-2 &amp; 4, Puce A, Hari R (2023)

Week 37:
No Teaching
Readings: None

Week 38:
Lesson 1: Workshop paradigm: Measuring visual subjective experience + MR Recordings
Class 1: Running an MEG analysis of visual responses
Readings: 
Ramsøy TZ, Overgaard M (2004) Introspection and subliminal perception.
    Phenomenology and the Cognitive Sciences 3:1–23.
    https://doi.org/10.1023/B:PHEN.0000041900.30172.e8

Sergent C, Baillet S, Dehaene S (2005)
    Timing of the brain events underlying access to consciousness
    during the attentional blink.
    Nature neuroscience 8:1391–400. https://doi.org/10.1038/nn1549

Week 39:
MEG workshop: Measuring and predicting visual subjective experience (see below)
Readings: Chapters 5-7, Puce A, Hari R (2023)

Week 40:
Lesson 2: Basic physiology and Evoked responses
Class 2: Evoked responses to different levels of subjective experience
Readings: Chapters 3, 10 &amp; 12, Puce A, Hari R (2023)

Week 41:
Lesson 3: Multivariate statistics
Class 3: Predicting subjective experience in sensor space
Readings: 
King J-R, Dehaene S (2014) Characterizing the dynamics of mental
    representations: the temporal generalization method.
    Trends in Cognitive Sciences 18:203–210.
    https://doi.org/10.1016/j.tics.2014.01.002

Sandberg K, Andersen LM, Overgaard M (2014) Using multivariate decoding to go beyond
    contrastive analyses in consciousness research.
    Front Psychol 5:1250. https://doi.org/10.3389/fpsyg.2014.01250

Week 42:
Autumn Break
Readings: Go dig up potatoes instead!

Week 43:
Lesson 4: Forward modelling and dipole estimation
Class 4: Creating a forward model
Readings: 
FieldTrip video: https://www.youtube.com/watch?v=3Q8HLHNieuI

Chapters 1-2 Sekihara K., Nagarajan S (2008)
</code></pre>
</div>
<div class="cell-output cell-output-display cell-output-markdown">
<p><strong>Mid-term evaluation</strong></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Week 44:
Lesson 5: Inverse modelling: Minimum-norm estimate
Class 5: Predicting subjective experience in source space
Readings: Chapter 3 Sekihara K., Nagarajan S (2008)

Week 45:
Lesson 6: Inverse modelling: Beamforming
Class 6: Predicting subjective experience in source space, continued
Readings: 
FieldTrip video: https://www.youtube.com/watch?v=pE0WAKd_Ve4

From a signal perspective: https://www.youtube.com/watch?v=A1n5Hhwtz78

Chapter 4 Sekihara K., Nagarajan S (2008)

Week 46:
Lesson 7: What about that other cortex? - the cerebellar one
Class 7: Oral presentations (part 1)
Readings: 
Sokolov AA, Miall RC, Ivry RB (2017) The Cerebellum:
    Adaptive Prediction for Movement and Cognition.
    Trends in Cognitive Sciences 21:313–332. https://doi.org/10.1016/j.tics.2017.02.005

Andersen LM, Dalal SS (2024) The role of the cerebellum in timing.
    Current Opinion in Behavioral Sciences 59:101427.
    https://doi.org/10.1016/j.cobeha.2024.101427

Week 47:
Lesson 8: Guest lecture: Laura Bock Paulsen: Respiratory analyses
Class 8: Oral presentations (part 2)
Readings: To be announced

Week 48:
Lesson 9: Sensors of the future
Class 9: Oral presentations (part 3)
Readings: 
Boto E, Holmes N, Leggett J, et al (2018)
    Moving magnetoencephalography towards real-world applications with a wearable system.
    Nature. https://doi.org/10.1038/nature26147

Video: https://spectrum.ieee.org/a-new-wearable-brain-scanner

Tierney TM, Levy A, Barry DN, et al (2021)
    Mouth magnetoencephalography: A unique perspective
    on the human hippocampus. NeuroImage 225:117443.
    https://doi.org/10.1016/j.neuroimage.2020.117443
</code></pre>
</div>
<div class="cell-output cell-output-display cell-output-markdown">
<p><strong>Final evaluation</strong></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Week 49:
Lesson 0 again: What was it all about?
Class 10: Oral presentations (part 4)
Readings: Baillet S (2017) Magnetoencephalography for brain electrophysiology
    and imaging. Nat Neurosci 20:327–339. https://doi.org/10.1038/nn.4504
</code></pre>
</div>
</div>
</section>
<section id="workshop" class="level4">
<h4 class="anchored" data-anchor-id="workshop">Workshop</h4>
<p>We will have 8 study groups with 4-5 people in each. We will have one participant from each group being the subject for the MR and the MEG</p>
<p>The workshop will take place at Aarhus University Hospital (Skejby). We meet at entrance J.<br>
<strong>September 19</strong>: acquisition of anatomical MR images for source reconstruction<br>
<strong>September 22-24</strong>: acquisition of MEG data. The paradigm and the protocol for the MEG preparation and MEG data acquisition will also be made available on <a href="https://github.com/ualsbombe/2025_advanced_cognitive_neuroscience">github</a>, as well as notebooks and other materials</p>
</section>
<section id="dependencies" class="level4">
<h4 class="anchored" data-anchor-id="dependencies">Dependencies</h4>
<p>Running analyses on the server: <a href="https://cloud.sdu.dk">UCLoud</a></p>
<p>To run MNE-Python locally, install MNE-Python from Miniconda (recommended; we will do this during Class 0). This will allow you to create advanced source model plots</p>
</section>
<section id="portfolio-exams" class="level4">
<h4 class="anchored" data-anchor-id="portfolio-exams">Portfolio exams</h4>
<p>The portfolio consists of three assignments</p>
<ol type="1">
<li><em>Video explainer to your peers:</em> <strong>Individual assignment (25 % of grade)</strong>:
<ul>
<li>Task: Make a video explainer of maximally 5 minutes; this should explain the underlying processes that give rise to a measurable magnetic field outside the head. The following concepts should be included: <em>post-synaptic potentials</em>, <em>current dipole</em>, <em>open field vs closed field</em>, <em>radial and tangential sources</em>, <em>volume conduction</em> and <em>evoked responses</em>. In general the level of the video explainer should be aimed at your peers and the relevant materials can be found in Chapters 1-3 of the textbook.<br>
</li>
<li>Evaluation criteria: to what degree are the concepts listed above <strong>clearly</strong>, <strong>succinctly</strong> and <strong>correctly</strong> described</li>
<li>Deadline for receiving feedback: Week 41 (Thursday 23.59)</li>
</ul></li>
<li><em>Report on MEG acquisition and MEG analysis:</em> <strong>Project group assignment (50 % of grade)</strong>:
<ul>
<li>Task: The report must include an <strong>introduction</strong>, based on relevant literature; operationalisable <strong>hypotheses</strong>; a clear <strong>methods</strong> section, which must describe the experiment and the data acquisition procedure; a succinct <strong>results</strong> section with both behavioural data and MEG data; a <strong>discussion</strong> addressing limitations and the suitability of the method for investigating subjective experience. Data from all 8 participants <strong>must</strong> be used and <strong>at least one</strong> analysis <strong>must</strong> be based on multivariate statistics.</li>
<li>Evaluation Criteria: to what degree has <strong>relevant</strong> literature been chosen for the introduction; to what degree has <strong>operationalisable</strong> hypotheses been formulated; to what degree has the methods section <strong>clearly</strong> described the experiment and the data acquisition procedure; to what degree are the results <strong>succinctly</strong> described; to what degree are the limitations and the suitability of the method <strong>relevantly</strong> described. (<strong>Remember</strong> to use all participants and to use a multivariate analysis)</li>
<li>Deadline for receiving feedback: Week 46 (Thursday 23.59)</li>
</ul></li>
<li><em>Oral presentation on set topic:</em> <strong>Project group assignment (25 % of grade)</strong>:
<ul>
<li><p>Task: Present on one of the topics below; note that the topics are assigned randomly to project groups during the course. The topics all have fixed dates.</p></li>
<li><p>Topics:</p>
<ul>
<li><p>The visual system, as understood through MEG</p>
<ul>
<li>Based on chapter 14, Puce A, Hari R (2023) (<strong>summary text</strong>)</li>
<li>one other text of your own choice among the ones presented in Figures 14.5, 14.8, 14.10 or 14.12 (<strong>experiment text</strong>)</li>
</ul></li>
<li><p>The auditory system, as understood through MEG</p>
<ul>
<li>Based on chapter 13, Puce A, Hari R (2023) (<strong>summary text</strong>)</li>
<li>one other text of your own choice among the ones presented in Figures 13.4 or 13.8 (<strong>experiment text</strong>)</li>
</ul></li>
<li><p>The somatosensory system, as understood through MEG</p>
<ul>
<li>Based on chapter 15, Puce A, Hari R (2023) (<strong>summary text</strong>)</li>
<li>one other text of your own choice among the ones presented in Figures 15.7, 15.8 or 15.9 (<strong>experiment text</strong>)</li>
</ul></li>
<li><p>Cognitive components and change detection</p>
<ul>
<li>Based on chapter 18, Puce A, Hari R (2023) (<strong>summary text</strong>)</li>
<li>one other text of your own choice among the ones presented in Figures 18.2, 18.4 or 18.5 (<strong>experiment text</strong>)</li>
</ul></li>
<li><p>Links between respiration, behaviour and MEG</p>
<ul>
<li><p>Kluger DS, Gross J (2021) Respiration modulates oscillatory neural network activity at rest. PLOS Biology 19:e3001457. https://doi.org/10.1371/journal.pbio.3001457 (<strong>summary text</strong>)</p></li>
<li><p>Kluger DS, Balestrieri E, Busch NA, Gross J (2021) Respiration aligns perception with neural excitability. eLife 10:e70907. https://doi.org/10.7554/eLife.70907 (<strong>experiment text</strong>)</p></li>
</ul></li>
<li><p>Development as understood through MEG</p>
<ul>
<li>Chen Y-H, Saby J, Kuschner E, et al (2019) Magnetoencephalography and the infant brain. NeuroImage 189:445–458. https://doi.org/10.1016/j.neuroimage.2019.01.059 (<strong>summary text</strong>)</li>
<li>Kuhl PK, Ramírez RR, Bosseler A, et al (2014) Infants’ brain responses to speech suggest Analysis by Synthesis. Proceedings of the National Academy of Sciences 111:11238–11245. https://doi.org/10.1073/pnas.1410963111 (<strong>experiment text</strong>)</li>
</ul></li>
<li><p>Language comprehension as understood through MEG</p>
<ul>
<li>Salmelin R (2010) MEG and Reading: From Perception to Linguistic Analysis. In: MEG: An Introduction to Methods. Oxford University Press, New York (<strong>summary text</strong>)</li>
<li>van Vliet M, Rinkinen O, Shimizu T, et al (2025) Convolutional networks can model the functional modulation of the MEG responses associated with feed-forward processes during visual word recognition. eLife 13:RP96217. https://doi.org/10.7554/eLife.96217 (<strong>experiment text</strong>)</li>
</ul></li>
<li><p>Subjective experience as understood through MEG</p>
<ul>
<li>Aru J, Bachmann T, Singer W, Melloni L (2012) Distilling the neural correlates of consciousness. Neuroscience &amp; Biobehavioral Reviews 36:737–746. https://doi.org/10.1016/j.neubiorev.2011.12.003 (<strong>summary text</strong>)</li>
<li>Shafto JP, Pitts MA (2015) Neural Signatures of Conscious Face Perception in an Inattentional Blindness Paradigm. J Neurosci 35:10940–10948. https://doi.org/10.1523/JNEUROSCI.0145-15.2015 (<strong>experiment text</strong>)</li>
</ul></li>
<li><p>Evaluation Criteria:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Criteria</th>
<th>Specifics</th>
<th>Percentage of score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Clear agenda</td>
<td>The structure is clear throughout; e.g.&nbsp;<em>method</em>, <em>results</em> and <em>interpretation</em> are clearly separated</td>
<td>10</td>
</tr>
<tr class="even">
<td>Time management</td>
<td>30 min for the presentation; 15 min for Q&amp;A. Make sure to allot time for each part of the chapter</td>
<td>5</td>
</tr>
<tr class="odd">
<td>Understanding of MEG fundamentals - e.g.&nbsp;basic physics, sensor types, source reconstruction</td>
<td>Make sure to use the right terminology and explain succinctly what terms mean</td>
<td>20</td>
</tr>
<tr class="even">
<td>Clear presentation of summary text</td>
<td>Extract core concepts from the chapter and explain core figures</td>
<td>20</td>
</tr>
<tr class="odd">
<td>Clear appraisal of experiment text</td>
<td>Summarise the study, explain the experimental design, explain results, the interpretation of the results and the limitations of the study</td>
<td>20</td>
</tr>
<tr class="even">
<td>Visual design</td>
<td>Coherent design, legible slides and no unnecessary information</td>
<td>5</td>
</tr>
<tr class="odd">
<td>Presentation skills</td>
<td>No reading aloud, control of the material</td>
<td>10</td>
</tr>
<tr class="even">
<td>Handling of Q&amp;A</td>
<td>How do you engage with the questions of fellow students? e.g.&nbsp;do you get the question, can you answer it and so on?</td>
<td>10</td>
</tr>
</tbody>
</table></li>
</ul></li>
</ul></li>
</ol>
</section>
<section id="feedback-practice" class="level4">
<h4 class="anchored" data-anchor-id="feedback-practice">Feedback practice</h4>
<p>To give you the opportunity to improve your videos (1) and your reports (2):</p>
<ul>
<li><p>I will give dedicated feedback on the individual videos <strong>if</strong> they are handed in on time</p></li>
<li><p>I will give dedicated feedback on the reports <strong>if</strong> they are handed in on time <strong>and if</strong> they are handed in as a group</p></li>
</ul>
</section>
<section id="from-the-academic-regulations" class="level4">
<h4 class="anchored" data-anchor-id="from-the-academic-regulations">From the academic regulations</h4>
<section id="description-of-qualifications" class="level5">
<h5 class="anchored" data-anchor-id="description-of-qualifications">Description of qualifications</h5>
<section id="purpose" class="level6">
<h6 class="anchored" data-anchor-id="purpose">Purpose:</h6>
<p>The purpose of the course is for students to acquire advanced knowledge about the structure and function of the brain, with a focus on how brain function contributes to cognitive function. The focus of the course is on advanced experimental methods in cognitive neuroscience, and students will conduct their own cognitive neuroimaging/cognitive neurophysiology research. Students will learn advanced statistical methods for analysing data acquired from the measurement of neural processes, with a focus on modelling techniques for relating neural data to cognitive functions.</p>
<p>The course includes 1) theory of neural and cognitive processes; 2) advanced statistical methodologies for analysing neuroimaging data; and 3) discussion of the theoretical relationships between neurobiological and cognitive brain processes.</p>
<p>This course builds on students’ knowledge of cognition, and their skills and competencies in using statistical methods.</p>
</section>
</section>
<section id="academic-objectives" class="level5">
<h5 class="anchored" data-anchor-id="academic-objectives">Academic objectives:</h5>
<p>In the evaluation of the student’s performance, emphasis is placed on the extent to which the student is able to:</p>
<section id="knowledge" class="level6">
<h6 class="anchored" data-anchor-id="knowledge">Knowledge:</h6>
<ul>
<li>describe the anatomy and physiology of the human brain, and explain the brain basis of cognitive function</li>
<li>contrast different cognitive neuroscience methods in terms of their strengths and weaknesses, and use this knowledge to develop appropriate experimental research for investigating different cognitive functions of the brain.</li>
</ul>
</section>
<section id="skills" class="level6">
<h6 class="anchored" data-anchor-id="skills">Skills:</h6>
<ul>
<li>run experiments using neuroimaging and/or neurophysiological measurement equipment</li>
<li>use advanced statistical methods to make inferences about cognitive brain functions from neuroimaging and/or neurophysiological data.</li>
</ul>
</section>
<section id="competences" class="level6">
<h6 class="anchored" data-anchor-id="competences">Competences:</h6>
<ul>
<li>independently identify the appropriate measurement technology and experimental designs for investigating different cognitive functions</li>
<li>identify cases in which statistical methods taught in the course can be applied to domains outside of cognitive neuroscience.</li>
</ul>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>